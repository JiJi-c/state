experiment:
  name: "vci_pretrain_${loss.name}_${model.nhead}_${model.nlayers}"
  local: "local"
  compiled: false
  deaware: false
  profile:
    enable_profiler: false
    profile_steps: [10, 100]
    max_steps: 110 # This is used only when profile is enabled
  num_epochs: 16
  num_nodes: 1
  num_gpus_per_node: 1
  port: 12399
  val_check_interval: 1000 # Number of steps between tests
  limit_val_batches: 100
  checkpoint:
    path: /scratch/ctc/ML/vci/checkpoint/pretrain
    save_top_k: 4
    monitor: trainer/train_loss
    every_n_train_steps: 1000

wandb:
  enable: True
  project: "vci"

embeddings:
  current: esm2-cellxgene
  esm2-cellxgene:
    all_embeddings: /large_storage/ctc/ML/data/cell/misc/Homo_sapiens.GRCh38.gene_symbol_to_embedding_ESM2.pt
    ds_emb_mapping: /large_storage/ctc/datasets/vci/training/gene_embidx_mapping.torch
    size: 5120

  evo2-scbasecamp:
    all_embeddings: /large_storage/ctc/projects/vci/scbasecamp/Evo2/all_species_Evo2.torch
    ds_emb_mapping: /large_storage/ctc/projects/vci/scbasecamp/Evo2/dataset_emb_idx_Evo2_fixed.torch
    valid_genes_masks: /large_storage/ctc/projects/vci/scbasecamp/Evo2/valid_gene_index_Evo2.torch
    size: 4096

  esm2-scbasecamp:
    all_embeddings: /large_storage/ctc/projects/vci/scbasecamp/ESM2/all_species_ESM2.torch
    ds_emb_mapping: /large_storage/ctc/projects/vci/scbasecamp/ESM2/dataset_emb_idx_ESM2.torch
    valid_genes_masks: /large_storage/ctc/projects/vci/scbasecamp/ESM2/valid_gene_index_ESM2.torch
    size: 1280

validations:
  diff_exp:
    enable: true
    eval_interval_multiple: 10
    obs_pert_col: gene
    obs_filter_label: non-targeting
    top_k_rank: 200
    method: null
    dataset: /large_storage/ctc/datasets/vci/validation/rpe1_top5000_variable.h5ad
    dataset_name: rpe1_top5000_variable

  perturbation:
    enable: true
    eval_interval_multiple: 10
    pert_col: gene
    ctrl_label: non-targeting
    dataset: /large_storage/ctc/datasets/vci/validation/replogle_perturbation.h5ad
    dataset_name: replogle_perturbation

dataset:
  name: "vci"
  seed: 42
  num_train_workers: 16
  num_val_workers: 4
  current: cellxgene

  cellxgene:
    data_dir: /large_experiments/goodarzilab/mohsen/cellxgene/processed
    ds_type: h5ad
    filter: false
    train: /scratch/ctc/ML/uce/h5ad_train_dataset.csv
    val: /scratch/ctc/ML/uce/h5ad_val_dataset.csv

  scbasecamp:
    ds_type: filtered_h5ad
    train: /large_storage/ctc/projects/vci/scbasecamp/scBasecamp_all.csv
    val: /large_storage/ctc/projects/vci/scbasecamp/scBasecamp_all.csv
    filter: true
    filter_by_species: null

  tahoe:
    ds_type: filtered_h5ad
    train: /scratch/ctc/ML/uce/full_train_datasets.csv
    val: /scratch/ctc/ML/uce/full_train_datasets.csv
    filter: true
    valid_genes_masks: null

  tahoe-h5ad:
    ds_type: filtered_h5ad
    train: /scratch/ctc/ML/uce/h5ad_train_dataset_tahoe.csv
    val: /scratch/ctc/ML/uce/h5ad_val_dataset_tahoe.csv
    filter: true
    valid_genes_masks: null

  # this is a map for each dataset's columns mapping them to a global gene ordering
  pad_length: 2048
  pad_token_idx: 0
  cls_token_idx: 3
  chrom_token_right_idx: 2
  P: 512
  N: 512
  num_cells:  36238464 # TODO: Is this required
  overrides:
    rpe1_top5000_variable: /large_storage/ctc/datasets/vci/validation/rpe1_top5000_variable.h5ad

tokenizer:
  token_dim: 5120

model:
  name: 'vci'
  batch_size: 128
  emsize: 512
  d_hid: 1024
  nhead: 16
  nlayers: 8
  dropout: 0.1
  output_dim:  512 # TODO: Is emsize different from this?
  use_flash_attention: true
  rda: false
  counts: false
  dataset_correction: false
  num_datasets: 1139
  ema: true
  ema_decay: 0.999
  ema_update_interval: 1000

task:
  mask: 0.2

optimizer:
  max_lr: 1e-4
  weight_decay: 0.01
  start: 0.33
  end: 1.0
  max_grad_norm: 0.8
  gradient_accumulation_steps: 1
  reset_lr_on_restart: false # LR is reset to start value on restart

loss:
  name: "cross_entropy" # mmd, cross_entropy, kl_divergence, mse, wasserstein, tabular
  apply_normalization: False
